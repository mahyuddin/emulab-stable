#! /usr/bin/env python

import os
import re
import sys
import stat
import time
import signal
import socket
import getopt

import MySQLdb

BASEDIR = "/var/nfstrace"
DBDIR = "/var/db/nfstrace"

DBNAME = "nfsdb"
DBUSER = "nfstrace"

try:
    DBPASS = open(os.path.join(BASEDIR, "dbpass")).read().strip()
    pass
except IOError:
    sys.stderr.write("error: permission denied\n")
    sys.exit(1)
    pass

INTERVAL = 5
VERBOSITY = 1

count = 0

def usage():
    return

try:
    opts, req_args = getopt.getopt(sys.argv[1:],
                                   "hvc:t:",
                                   [ "help", "verbose", "count=", ])
    
    for opt, val in opts:
        if opt in ("-h", "--help"):
            usage()
            sys.exit()
            pass
        elif opt in ("-v", "--verbose"):
            VERBOSITY = VERBOSITY + 1
            pass
        elif opt in ("-c", "--count"):
            count = int(val)
            pass
        pass
    
    if len(req_args) < 1:
        raise getopt.error('error: too few arguments')

    pass
except getopt.error, e:
    print e.args[0]
    usage()
    sys.exit(2)
    pass

IDX_TIMESTAMP = 0
IDX_SRC_IP = 1
IDX_DST_IP = 2
IDX_PKT_TYPE = 3
IDX_REQ_REPLY = 4
IDX_ID = 5
IDX_COMMAND = 7
IDX_BODY_START = 8

TABLES = [
    "mounts",
    "mount_replies",
    "reads",
    "writes",
    "creates",
    "create_replies",
    "mkdirs",
    "mkdir_replies",
    "readlinks",
    "readlink_replies",
    "removes",
    "remove_replies",
    "rmdirs",
    "rmdir_replies",
    "renames",
    "rename_replies",
    "lookups",
    "lookup_replies",
    ]

MAX_FH_LENGTH = 64

con = MySQLdb.connect(db = DBNAME, user = DBUSER, passwd = DBPASS)

cur = con.cursor()

def convert_ip(hexip):
    hexip = hexip.split(".")[0]
    comp = []
    for lpc in range(0, 8, 2):
        comp.append(str(int(hexip[lpc:lpc + 2], 16)))
        pass
    retval = ".".join(comp)
    
    return retval

def body_to_dict(line):
    retval = { "fn" : None, "tcount" : None }
    for lpc in range(0, len(line), 2):
        retval[line[lpc]] = line[lpc + 1]
        pass
    
    return retval

def padfh(fh):
    retval = fh
    
    if len(retval) < MAX_FH_LENGTH:
        retval = fh + ("0" * (MAX_FH_LENGTH - len(fh)))
        pass
    
    return retval

def getfn(fn):
    return (fn[1:-1]).replace(",","\\,")

class Parser:

    def __init__(self):
        self.first_timestamp = 0
        self.lookups = {}

        self.data_files = {}
        self.row_counts = {}
        for tab in TABLES:
            self.data_files[tab] = open(os.path.join(DBDIR, tab), 'w')
            self.data_files[tab].truncate(0)
            self.row_counts[tab] = 0
            pass
        return

    def load_files(self):
        for value in self.lookups.values():
            self.write_row("lookups", value)
            pass
        self.lookups.clear()
        
        for tab in TABLES:
            self.data_files[tab].flush()

            print ("    Table: " + tab.ljust(18) + " \t"
                   + `self.row_counts[tab]` + " record(s)")
            cur.execute("LOAD DATA INFILE %s REPLACE INTO TABLE " + tab +
                        " FIELDS TERMINATED BY ','",
                        (self.data_files[tab].name,))

            self.data_files[tab].seek(0)
            self.data_files[tab].truncate(0)
            self.row_counts[tab] = 0
            pass

        return

    def clear_timestamp(self):
        self.first_timestamp = 0
        return

    def nextline(self, line):
        sl = line.split()
        cmd = sl[IDX_COMMAND]
        try:
            if not self.first_timestamp:
                self.first_timestamp = sl[IDX_TIMESTAMP]
                pass
            if sl[IDX_REQ_REPLY] in ("C1", "C2", "C3") :
                body = body_to_dict(sl[IDX_BODY_START:-6])
                self.dispatch("handle_" + cmd, sl, body)
                pass
            elif sl[IDX_REQ_REPLY] in ("R1", "R2", "R3"):
                body = body_to_dict(sl[IDX_BODY_START + 1:-10])
                self.dispatch("handle_" + cmd + "_reply", sl, body)
                if sl[IDX_BODY_START] == "OK" and cmd != "mnt":
                    self.update_file_checkpoint(sl, body)
                    pass
                pass
            pass
        except:
            print "line " + line
            raise
        
        return

    def write_row(self, tab, data):
        self.data_files[tab].write(",".join(data))
        self.data_files[tab].write("\n")
        self.row_counts[tab] += 1
        return

    def dispatch(self, method_name, sl, body):
        retval = None
        if "error" in body:
            print "Bad line " + sl.join(" ")
            pass
        elif hasattr(self, method_name):
            method = getattr(self, method_name)
            retval = method(sl, body)
            pass
        else:
            # print "unhandled " + method_name
            pass
        
        return retval

    def update_file_checkpoint(self, sl, body):
        if False and body.has_key("fh"):
            data = (
                sl[IDX_TIMESTAMP],
                body["fh"],
                int(body["ftype"], 16),
                int(body["mode"], 16),
                int(body["nlink"], 16),
                int(body["uid"], 16),
                int(body["gid"], 16),
                int(body["size"], 16),
                int(body["rdev"], 16),
                int(body["fsid"], 16),
                int(body["fileid"], 16),
                int(body["atime"].split(".")[0]),
                int(body["mtime"].split(".")[0]),
                int(body["ctime"].split(".")[0]),
                )
            cur.execute("REPLACE INTO file_checkpoint (timestamp, fh, ftype, mode, nlink, uid, gid, size, rdev, fsid, fileid, atime, mtime, ctime) VALUES (" + ",".join(("%s",) * len(data)) + ")", data)
            pass
        
        return
    
    def handle_mnt(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            getfn(body["fn"]),
            body["euid"],
            body["egid"])
        self.write_row("mounts", data)
        
        return

    def handle_mnt_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            pass
        
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_DST_IP]),
            status,
            padfh(body.get("fh", '')))
        self.write_row("mount_replies", data)
        
        return
    
    def handle_read(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            str(int(body["count"], 16)),
            body["euid"],
            body["egid"])
        self.write_row("reads", data)
        
        return

    def handle_write(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            str(int((body["tcount"] or body["count"]), 16)),
            body["euid"],
            body["egid"])
        self.write_row("writes", data)
        
        return

    def handle_readlink(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            body["euid"],
            body["egid"])
        self.write_row("readlinks", data)
        
        return

    def handle_readlink_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            fn = getfn(body["fn"] or body["name"])
            pass
        else:
            fn = ""
            pass

        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_DST_IP]),
            status,
            fn)
        self.write_row("readlink_replies", data)
        
        return
    
    def handle_create(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            getfn(body["fn"] or body["name"]),
            str(int(body.get("mode", "0"), 16)), # XXX
            body["euid"],
            body["egid"])
        self.write_row("creates", data)
        
        return

    def handle_create_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            pass
        
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_DST_IP]),
            status,
            padfh(body.get("fh", '')))
        self.write_row("create_replies", data)
        
        return
    
    def handle_mkdir(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            getfn(body["fn"] or body["name"]),
            str(int(body.get("mode", "0"), 16)), # XXX
            body["euid"],
            body["egid"])
        self.write_row("mkdirs", data)
        
        return

    def handle_mkdir_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            pass
        
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_DST_IP]),
            status,
            padfh(body.get("fh", '')))
        self.write_row("mkdir_replies", data)
        
        return
    
    def handle_remove(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            getfn(body["fn"] or body["name"]),
            body["euid"],
            body["egid"])
        self.write_row("removes", data)
        
        return

    def handle_remove_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            pass
        
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_DST_IP]),
            status)
        self.write_row("remove_replies", data)
        
        return

    def handle_rmdir(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            getfn(body["fn"] or body["name"]),
            body["euid"],
            body["egid"])
        self.write_row("rmdirs", data)
        
        return

    def handle_rmdir_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            pass
        
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_DST_IP]),
            status)
        self.write_row("rmdir_replies", data)
        
        return

    def handle_rename(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            getfn(body.get("fn", None) or body["name"]),
            padfh(body["fh2"]),
            getfn(body.get("fn2", None) or body["name2"]),
            body["euid"],
            body["egid"])
        self.write_row("renames", data)
        
        return

    def handle_rename_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            pass
        
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_DST_IP]),
            status)
        self.write_row("rename_replies", data)
        
        return

    def handle_lookup(self, sl, body):
        data = (
            sl[IDX_TIMESTAMP],
            sl[IDX_ID],
            convert_ip(sl[IDX_SRC_IP]),
            padfh(body["fh"]),
            getfn(body["fn"] or body["name"]),
            body["euid"],
            body["egid"])
        self.lookups[(data[1], data[2])] = data
        
        return

    def handle_lookup_reply(self, sl, body):
        status = sl[IDX_BODY_START]
        if status == "OK":
            status = "0"
            data = (
                sl[IDX_TIMESTAMP],
                sl[IDX_ID],
                convert_ip(sl[IDX_DST_IP]),
                status,
                padfh(body.get("fh", '')))
            
            key = (data[1], data[2])
            if self.lookups.has_key(key):
                self.write_row("lookups", self.lookups[key])
                del self.lookups[key]
                pass
            
            self.write_row("lookup_replies", data)
            pass
        else:
            key = (sl[IDX_ID], convert_ip(sl[IDX_DST_IP]))
            if self.lookups.has_key(key):
                del self.lookups[key]
                pass
            pass
        
        return
    
    pass

def update_handle_map(ts):
    print "    mounts"
    cur.execute("REPLACE INTO handle_map (fh, fn, timestamp, valid) "
                "SELECT mr.fh,m.fn,m.timestamp,1 "
                "FROM mount_replies as mr "
                "INNER JOIN mounts as m on (m.node_ip=mr.node_ip and "
                "  m.id=mr.id) "
                "WHERE mr.status=0 and mr.timestamp>=%s",
                (ts,))
    
    print "    lookups"
    cur.execute("REPLACE INTO temp_handle_map "
                "  (fh, parent, fn, timestamp, valid) "
                "SELECT lr.fh,l.fh,l.fn,MAX(l.timestamp),1 "
                "FROM lookup_replies as lr "
                "INNER JOIN lookups as l on (l.node_ip=lr.node_ip and "
                "  l.id=lr.id) "
                "LEFT JOIN handle_map as hm on hm.fh=lr.fh "
                "WHERE lr.status=0 and lr.timestamp>=%s and "
                "  (hm.fh is null or lr.timestamp > hm.timestamp) "
                "GROUP BY lr.fh,l.fh,l.fn",
                (ts,))
    cur.execute("REPLACE INTO handle_map (fh, parent, fn, timestamp, valid) "
                "SELECT * from temp_handle_map")
    cur.execute("DELETE FROM temp_handle_map")
    
    print "    creates"
    cur.execute("REPLACE INTO temp_handle_map "
                "  (fh, parent, fn, timestamp, valid) "
                "SELECT lr.fh,l.fh,l.fn,MAX(l.timestamp),1 "
                "FROM create_replies as lr "
                "INNER JOIN creates as l on (l.node_ip=lr.node_ip and "
                "  l.id=lr.id) "
                "LEFT JOIN handle_map as hm on hm.fh=lr.fh "
                "WHERE lr.status=0 and lr.timestamp>=%s and "
                "  (hm.fh is null or lr.timestamp > hm.timestamp) "
                "GROUP BY lr.fh,l.fh,l.fn",
                (ts,))
    cur.execute("REPLACE INTO handle_map (fh, parent, fn, timestamp, valid) "
                "SELECT * from temp_handle_map")
    cur.execute("DELETE FROM temp_handle_map")
    
    print "    mkdirs"
    cur.execute("REPLACE INTO temp_handle_map "
                "  (fh, parent, fn, timestamp, valid) "
                "SELECT lr.fh,l.fh,l.fn,MAX(l.timestamp),1 "
                "FROM mkdir_replies as lr "
                "INNER JOIN mkdirs as l on (l.node_ip=lr.node_ip and "
                "  l.id=lr.id) "
                "LEFT JOIN handle_map as hm on hm.fh=lr.fh "
                "WHERE lr.status=0 and lr.timestamp>=%s and "
                "  (hm.fh is null or lr.timestamp > hm.timestamp) "
                "GROUP BY lr.fh,l.fh,l.fn",
                (ts,))
    cur.execute("REPLACE INTO handle_map (fh, parent, fn, timestamp, valid) "
                "SELECT * from temp_handle_map")
    cur.execute("DELETE FROM temp_handle_map")
    
    print "    renames"
    cur.execute("REPLACE INTO temp_handle_map "
                "  (fh, parent, fn, timestamp, valid) "
                "SELECT hm.fh,l.from_fh,l.from_fn,MAX(l.timestamp),0 "
                "FROM rename_replies as lr "
                "INNER JOIN renames as l on (l.node_ip=lr.node_ip and "
                "  l.id=lr.id) "
                "INNER JOIN handle_map as hm on (hm.parent=l.from_fh and "
                "  hm.fn=l.from_fn) "
                "WHERE lr.status=0 and lr.timestamp>=%s and "
                "  lr.timestamp > hm.timestamp "
                "GROUP BY hm.fh,l.from_fh,l.from_fn",
                (ts,))
    cur.execute("REPLACE INTO handle_map (fh, parent, fn, timestamp, valid) "
                "SELECT * from temp_handle_map")
    cur.execute("DELETE FROM temp_handle_map")
    
    cur.execute("REPLACE INTO temp_handle_map "
                "  (fh, parent, fn, timestamp, valid) "
                "SELECT hm.fh,l.to_fh,l.to_fn,MAX(l.timestamp),1 "
                "FROM rename_replies as lr "
                "INNER JOIN renames as l on (l.node_ip=lr.node_ip and "
                "  l.id=lr.id) "
                "LEFT JOIN handle_map as hm on (hm.parent=l.from_fh and "
                "  hm.fn=l.from_fn) "
                "WHERE lr.status=0 and lr.timestamp>=%s and "
                "  (hm.fh is null or lr.timestamp > hm.timestamp) "
                "GROUP BY hm.fh,l.to_fh,l.to_fn",
                (ts,))
    cur.execute("REPLACE INTO handle_map (fh, parent, fn, timestamp, valid) "
                "SELECT * from temp_handle_map")
    cur.execute("DELETE FROM temp_handle_map")
    
    return

parser = Parser()
name2stamp = {}
updates = 0

def update_files(files):
    global updates
    
    for fn in files:
        try:
            st = os.stat(fn)
            mtime = st[stat.ST_MTIME]
            if mtime > name2stamp.get(fn, 0):
                print "Reading " + fn
                updates += 1
                name2stamp[fn] = st[stat.ST_MTIME]
                fh = open(fn)
                for line in fh:
                    parser.nextline(line)
                    pass
                fh.close()

                print "  Loading into DB..."
                parser.load_files()

                print "  Update handle map..."
                update_handle_map(parser.first_timestamp)

                print "  Update dropped files..."
                cur.execute("REPLACE INTO file_dropped "
                            "(fh, node_ip, last_remove) "
                            "SELECT hm.fh,r.node_ip,MAX(r.timestamp) "
                            "  FROM removes as r "
                            "INNER JOIN handle_map as hm on "
                            "  (hm.parent=r.fh and hm.fn=r.fn) "
                            "INNER JOIN remove_replies as rr on "
                            "  (rr.node_ip=r.node_ip and rr.id=r.id) "
                            "WHERE rr.timestamp >= %s and rr.status=0 "
                            "GROUP BY r.node_ip,hm.fh",
                            (parser.first_timestamp,))
                
                cur.execute("REPLACE INTO file_dropped "
                            "(fh, node_ip, last_remove) "
                            "SELECT hm.fh,r.node_ip,MAX(r.timestamp) "
                            "  FROM rmdirs as r "
                            "INNER JOIN handle_map as hm on "
                            "  (hm.parent=r.fh and hm.fn=r.fn) "
                            "INNER JOIN rmdir_replies as rr on "
                            "  (rr.node_ip=r.node_ip and rr.id=r.id) "
                            "WHERE rr.timestamp >= %s and rr.status=0 "
                            "GROUP BY r.node_ip,hm.fh",
                            (parser.first_timestamp,))

                print "  Update accessed links..."
                cur.execute("REPLACE INTO link_access "
                            "(fh, fn, node_ip, last_access) "
                            "SELECT r.fh,rr.fn,r.node_ip,MAX(rr.timestamp) "
                            "FROM readlink_replies as rr "
                            "INNER JOIN readlinks as r on "
                            "  (r.node_ip=rr.node_ip and r.id=rr.id) "
                            "WHERE rr.timestamp >= %s "
                            "GROUP BY r.fh,r.node_ip",
                            (parser.first_timestamp,))
                
                print "  Update accessed files..."
                cur.execute("REPLACE INTO file_access "
                            "(fh, node_ip, last_access) "
                            "SELECT fh,node_ip,MAX(timestamp) FROM reads "
                            "WHERE timestamp >= %s "
                            "GROUP BY fh,node_ip",
                            (parser.first_timestamp,))
                cur.execute("REPLACE INTO file_access "
                            "(fh, node_ip, last_access) "
                            "SELECT fh,node_ip,MAX(timestamp) FROM writes "
                            "WHERE timestamp >= %s "
                            "GROUP BY fh,node_ip",
                            (parser.first_timestamp,))

                print "  Delete old data..."
                for tab in TABLES:
                    cur.execute("DELETE FROM " + tab + " WHERE timestamp<%s",
                                (float(parser.first_timestamp) - (5 * 60),))
                    pass

                if updates % 10 == 0:
                    print "  Garbage collecting handle map"
                    cur.execute(
                        "SELECT hm1.fh FROM handle_map as hm1 "
                        "LEFT JOIN file_access as fa on fa.fh=hm1.fh "
                        "LEFT JOIN link_access as la on la.fh=hm1.fh "
                        "LEFT JOIN handle_map as hm2 on hm2.parent=hm1.fh "
                        "WHERE hm1.timestamp < "
                        "  (UNIX_TIMESTAMP() - (2 * 24 * 60 * 60)) and "
                        "  fa.fh is null and la.fh is null and hm2.fh is null "
                        "GROUP BY hm1.fh")
                    for res in cur:
                        cur.execute("DELETE FROM handle_map WHERE fh=%s", res)
                        pass
                    pass

                print "  Done."
                
                parser.clear_timestamp()
                pass
            pass
        except OSError, e:
            pass
        except IOError, e:
            pass
        pass

    return

try:
    lpc = 0

    while (count == 0) or (lpc < count):
        update_files(req_args)
        con.commit()
        
        time.sleep(INTERVAL)
        lpc = lpc + 1
        pass
    pass
finally:
    con.commit()
    pass
