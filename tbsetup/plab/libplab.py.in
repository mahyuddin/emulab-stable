# -*- python -*-
"""
Library for interfacing with Plab and, specifically, dslice.  This
abstracts out the concepts of Plab central, slices, and nodes.  All
data (except static things like certificates) is kept in the Emulab
DB.  Unlike the regular dslice svm, this one supports dynamically
changing which nodes are in a slice.

This requires an already obtained dslice certficate and key.  By default
it expects to find these in the @prefix@/etc/plab/ subdirectory.
"""

import sys
sys.path.append("@prefix@/lib/dslice")
sys.path.append("@prefix@/lib/dslice/dslice")
sys.path.append("@prefix@/lib/dslice/HTMLgen")

import os, pwd, time
import MySQLdb
import agent, agentproxy
import nodemgr, nodemgrproxy
import lease
import string
import traceback
import xmlrpclib
import socket
import signal

from warnings import warn

#
# Constants
#

LEASELEN = 14*24*60*60   # Two weeks (maximum lease length)
AGENTIP = "dslice.planet-lab.org"
RENEW_TIME = 2*24*60*60  # Renew two days before lease expires

DEF_TIMEOUT    = 1*60     # default timeout interval
RENEW_TIMEOUT = 1*60     # give the node manager a minute to respond to renew
FREE_TIMEOUT  = 1*60     # give the node manager a minute to respond to free

TBOPS = "@TBOPSEMAIL@".replace("\\","")
MAILTAG = "@THISHOMEBASE@"
SCRIPTNAME = "Unknown" # should see if we can get the toplevel script name

RESERVED_PID = "emulab-ops"
RESERVED_EID = "plabnodes"
MONITOR_PID  = "emulab-ops"
MONITOR_EID  = "plab-monitor"

MAGIC_INET2_GATEWAYS = ("205.124.237.10", )
MAGIC_INET_GATEWAYS = ("205.124.249.123", "205.124.249.113")
LOCAL_PLAB_DOMAIN = ".flux.utah.edu"
LOCAL_PLAB_LINKTYPE = "pcplabinet2"
#ALLOWED_NODES = ("155.98.35.3", "12.46.129.22")
ALLOWED_NODES = ()
NUMVNODES = 20

PLABNODE = "@prefix@/sbin/plabnode"
DEFAULT_DATA_PATH = "@prefix@/etc/plab/" # ensure this ends in a slash
SSH = "@prefix@/bin/sshtb"
NAMED_SETUP = "@prefix@/sbin/named_setup"

HTTPD_SITE = "http://localhost:"
HTTPD_PORT = "1492"
HTTP_PATH = "/" # ensure this ends in a slash
ROOTBALL_HTTP_URLPATH = HTTPD_SITE + HTTPD_PORT + HTTP_PATH

DEF_ROOTBALL_NAME = "plabroot-8.tgz"

#
# How many seconds to sleep between failures and how many times to try
# commands to both the dslice agent, and individual node managers.
#
DEF_SLEEPINT = 5
DEF_TRIES = 3

verbose = 0
debug = 0

#
# Disable line buffering
#
sys.stdout = os.fdopen(sys.stdout.fileno(), sys.stdout.mode, 0)

#
# Ensure SIGPIPE doesn't bite us:
#
signal.signal(signal.SIGPIPE, signal.SIG_IGN)

#
# General library functions
#

def handleArgs(args):
    """
    Takes a list of command-line arguments, interprets those at the
    beginning that are meant for libplab (-vd), and returns the remainder
    of the arguments.
    """
    global verbose, debug
    import getopt
    opts, args = getopt.getopt(args, "vd")

    for o, a in opts:
        if o == "-v":
            verbose = 1
        if o == "-d":
            debug = 1
    return args


def SENDMAIL(To, Subj, Msg, From = None, Headers = None, Files = ()):
    """
    Sends email to someone about something :)

    This function is similar to its perl library counterpart.

    ARGS:

     To:      <string> Email address of recipient.
     Subj:    <string> Subject of email.
     Msg:     <string> Message text.
     From:    <string> Email address of sender (optional).
     Headers: <string> Extra header strings (must newline terminate all but
                       the last one) (optional).
     Files:   <tuple>  List of files to append to message body (optional).
     
    RETURNS:
     Always returns 1

    SIDE EFFECTS:
     Can raise exceptions via called methods/functions.
    """
    Tag = MAILTAG.upper()
    # damn, no good way to tell if this fails
    sm = os.popen("/usr/sbin/sendmail -t", "w")
    
    #
    # Sendmail will figure this out if not given.
    # 
    if From:
	sm.write("From: %s\n" % From)
        
    if Headers:
	sm.write("%s\n" % Headers)
        
    sm.write("X-NetBed: %s\n" % SCRIPTNAME)
    sm.write("To: %s\n" % To)
    sm.write("Subject: %s: %s\n" % (Tag, Subj))
    sm.write("\n")
    sm.write("%s\n" % Msg)
    sm.write("\n")

    if len(Files):
        for fname in Files:
            try:
                infile = open(fname)
            except IOError:
                continue
            
            sm.write("\n--------- %s --------\n" % fname)

            for line in infile.readlines():
                sm.write(line)
            
            infile.close()
    
    sm.write("\n")
    sm.close()
    
    return 1

#
# Termination signals, and global var to track if we got one when
# they are disabled with disable_sigs
#
TERMSIGS = (signal.SIGTERM, signal.SIGHUP, signal.SIGINT)
gotsig = 0

class SignalInterrupt(Exception):
    def __init__(self, signum):
        self.signum = signum

#
# Keep track of last terminal signal received
#
def localSigHandler(signum, frame):
    """
    Keep track of received signals.
    """
    global gotsig
    gotsig = signum
    if verbose:
        print "Caught signal %s" % signum

def disable_sigs(sigs):
    """
    Put signal watcher into place.  I wish you could just temporarily
    block (but not ignore) signals in python - alas.
    """
    osigs = {}
    for sig in sigs:
        osigs[sig] = signal.signal(sig, localSigHandler)
    return osigs

def enable_sigs(osigs):
    """
    Reinstate old signal handlers and then raise an exception if
    one was caught while we had them disabled.
    """
    global gotsig
    
    for sig,handler in osigs.items():
        signal.signal(sig, handler)

    if gotsig:
        tmp = gotsig
        gotsig = 0
        raise SignalInterrupt(tmp)


#
# Local timeout error class and generic alarm handler
# Also listed are a couple of state saving vars for the alarm handler
# when the local one is installed.  The *_alarm calls are nestable
#
class TimeoutError: pass
def alrmhandler(signum, frame):
    if debug:
        print "Timeout! Raising TimeoutError."
    raise TimeoutError

oalrmhandlerstk = []  # alarm handler stack
oalrmtmostk = []      # alarm timeout stack

def enable_alarm():
    """
    Install a little local alarm handler, stash away old one, and
    it's pending alarm timeout (if set).
    """
    global oalrmhandlerstk, oalrmtmostk
    oalrmhandlerstk.append(signal.signal(signal.SIGALRM, alrmhandler))
    oalrmtmo = signal.alarm(0)
    if oalrmtmo:
        oalrmtmo += time.time()
    oalrmtmostk.append(oalrmtmo)

def disable_alarm():
    """
    Restore old handler and timeout.  If the old timeout has passed, warn,
    and send the alarm signal immediately.
    """
    signal.signal(signal.SIGALRM, oalrmhandlerstk.pop())
    oalrmtmo = oalrmtmostk.pop()
    if oalrmtmo:
        diff = oalrmtmo - time.time()
        if diff > 0:
            signal.alarm(diff)
        else:
            warn("missed a timeout deadline, sending SIGALRM immediately!")
            os.kill(os.getpid(), signal.SIGALRM)
    

def ForkCmd(cmd, args=(), timeout=DEF_TIMEOUT,
            disable_sigs_parent=(), disable_sigs_child=()):
    """
    Fork and run the given command, and optionally timeout in the parent.

    ARGS:
     cmd: <bound method | function> command to run.
     args: <tuple> arguments to the above command.
     timeout: <int> seconds to wait for child/command to complete
              before killing it off and returning
     disable_sigs_parent: <tuple of ints> signals to disable in parent
     disable_sigs_child:  <tuple of ints> signals to disable in child

    RETURNS:
     return code of forked command (1 if exception is caught, or different
     if user supplied command does its own exit()).

    SIDE EFFECTS:
     Forks child process to run provided command.  Blocks signals
     if instructed to with disable_sigs() (does an enable_sigs() before
     returning).
    """
    osigs = None
    childpid = os.fork()

    # parent
    if childpid:
        gotexc = 0
        exval = (0,0)
        if disable_sigs_parent:
            osigs = disable_sigs(disable_sigs_parent)
        enable_alarm()
        signal.alarm(timeout)
        while 1:
            try:
                exval = os.waitpid(childpid, 0)
            except TimeoutError:
                print "Timeout waiting for command completion: %s" % \
                      cmd.func_name
                gotexc = 1
                break
            except OSError, e:
                if e.errno == 4:
                    continue
                else:
                    gotexc = 1
                    break
            except:
                gotexc = 1
                break
            else:
                break

        if gotexc:
            signal.alarm(0)
            tb = "".join(traceback.format_exception_only(*sys.exc_info()[:2]))
            print "Exception caught while trying to " \
                  "run command %s\n%s" % (cmd.func_name, tb)
            try: os.kill(childpid, signal.SIGUSR1)
            except: pass
            try: os.wait()
            except: pass
        else:
            if debug:
                if os.WIFEXITED(exval[1]):
                    print "Process complete, exit value: %d" % \
                          os.WEXITSTATUS(exval[1])
                if os.WIFSIGNALED(exval[1]):
                    print "Process signalled: %d" % \
                          os.WTERMSIG(exval[1])

        disable_alarm()
        if osigs:
            enable_sigs(osigs)
        return gotexc | exval[1]

    # child
    else:
        def sigusrexit(signum, frame):
            if debug:
                print "Received SIGUSR1, bailing out"
            os._exit(1)

        retval = 1
        if disable_sigs_child:
            osigs = disable_sigs(disable_sigs_child)
        signal.signal(signal.SIGUSR1, sigusrexit)
        try:
            if type(args) == tuple:
                retval = cmd(*args)
            else:
                retval = cmd(args)
        except:
            traceback.print_exception(*sys.exc_info())
        os._exit(retval)


#
# Database functions
#

__dbName = "@TBDBNAME@"
__dbQueryMaxtries = 1
__dbConnMaxtries = 5

__dbConnection = None

def TBDBConnect():
    global __dbConnection
    
    if __dbConnection:
        return

    # Create a DB username for accounting purposes
    uid = os.getuid()
    try:
        name = pwd.getpwuid(uid)[0]
    except KeyError:
        name = "uid%d" % uid
    dbuser = "%s:%s:%d" % (sys.argv[0], name, os.getpid())

    if debug:
        print "Connecting to db %s as %s" % (__dbName, dbuser)

    # Connect, with retries
    for tries in range(__dbConnMaxtries):
        try:
            __dbConnection = MySQLdb.connect(db = __dbName, user = dbuser)
        except:
            time.sleep(1)
        else:
            break
    else:
        raise RuntimeError, "Cannot connect to DB after several attempts!"

def DBQueryFatal(queryPat, querySub = (), asDict = False):
    TBDBConnect()
    
    if asDict:
        cursor = __dbConnection.cursor(MySQLdb.cursors.DictCursor)
    else:
        cursor = __dbConnection.cursor()

    if debug:
        print "Executing DB query %s" % queryPat

    tries = __dbQueryMaxtries
    while tries:
        try:
            cursor.execute(queryPat, querySub)
            ret = cursor.fetchall()
            if debug:
                rs = `ret`
                if len(rs) > 60:
                    rs = rs[:60] + "..."
                print "Result: %s" % rs
            return ret
        except MySQLdb.MySQLError:
            tries -= 1
            if tries == 0:
                raise
            else:
                time.sleep(1)
                try:
                    __dbConnection.ping()
                except MySQLdb.MySQLError: pass
    tbmsg = "".join(traceback.format_exception(*sys.exc_info()))
    SENDMAIL(TBOPS, "DB query failed", "DB query failed:\n\n%s" % tbmsg)
    raise RuntimeError, "Aah!  Escaped DBQueryFatal loop"

def DBQuery(*args):
    try:
        ret = DBQueryFatal(*args)
    except MySQLdb.MySQLError:
        return None


def tryXmlrpcCmd(cmd, args = (),
                 inittries = DEF_TRIES,
                 sleepint = DEF_SLEEPINT,
                 raisefault = False):
    """
    This helper/wrapper function's job is to invoke the commands to the
    central agent, or local node manager, taking steps to retry and
    recover from failure.

    ARGS:
     cmd:        <bound method | function> command to try.
     args:       <tuple> arguments to pass to the above command.
     inittries:  <int> number of retries before the function gives up
                 and reraises the last caught exception.
     sleepint:   <int> how long to sleep (in seconds) between retries.
     raisefault: <boolean> indicates whether or not to reraise an
                 xmlrpclib Fault exception when caught.  When true it
                 also adds a new 'triesleft' member to the Fault class
                 instance containing the number of attempts this
                 function had remaining when the Fault exception was
                 encountered.

    RETURNS:
     This function returns the result returned by the passed in command.

    SIDE EFFECTS:
     Invokes the passed in command with the passed in arguments.
     Catches protocol/socket exceptions for command retry.
     (Optionally) catches xmlrpclib.Fault exceptions for command retry.
     Adds a 'triesleft' member to all exceptions reraised prior to tries=0.
     Understands TimeoutError exceptions, and will reraise them.
     
    """

    tries = inittries
    
    if debug:
        print "About to perform command %s with args:\n\t%s" % \
              (cmd, args)
    while 1:
        tries = tries - 1
        try:
            if args:
                # have to differentiate since the '*' operator wants
                # a tuple - throws an exception if its operand isn't
                if type(args) == tuple:
                    return cmd(*args)
                else:
                    return cmd(args)
            else:
                return cmd()
        except xmlrpclib.Fault, e:
            if raisefault:
                e.triesleft = tries
                raise xmlrpclib.Fault, e
            print "XML-RPC Fault happened while executing agent " \
                  "command: %s args: %s" % (cmd.func_name, args)
            print "\tCode: %s, Error: %s" % (e.faultCode, e.faultString)
        except TimeoutError, e:
            if debug:
                print "Caught a timeout error, setting triesleft and raising."
            e.triesleft = tries
            raise TimeoutError, e
        except (socket.error, xmlrpclib.ProtocolError), e:
            print "Encountered problem communicating with agent " \
                  "while executing command: %s args: %s" % \
                  (cmd.func_name, args)
            if debug:
                print "Exception is of type: %s" % e
                    
        if tries > 0:
            print "Sleeping for %s seconds, then retrying %s command" % \
                  (sleepint, cmd.func_name)
            time.sleep(sleepint)
        else:
            # XXX: perhaps this should raise its own, new type of
            # exception.
            print "Giving up after %s tries" % inittries
            raise


#
# Plab abstraction
#

class Plab:
    def __init__(self, keyfile = DEFAULT_DATA_PATH + "key.pem",
                 pubkeyfile = DEFAULT_DATA_PATH + "pubkey.pem",
                 certfile = DEFAULT_DATA_PATH + "cert.pem",
                 cacertfile = DEFAULT_DATA_PATH + "cacert.pem"):
        for file in (keyfile, pubkeyfile, certfile, cacertfile):
            if not os.path.exists(file):
                raise RuntimeError, "Key or cert %s does not exist" % file
        self.keyfile, self.pubkeyfile, self.certfile, self.cacertfile = \
                      keyfile, pubkeyfile, certfile, cacertfile
        self.__agentProxy = None

    def createSlice(self, pid, eid):
        """
        Slice factory function
        """
        slice = Slice(self, pid, eid)
        slice._create()
        return slice

    def loadSlice(self, pid, eid):
        """
        Slice factory function
        """
        slice = Slice(self, pid, eid)
        slice._load()
        return slice

    def getFree(self, ignorenew = False):
        """
        Finds out which Plab nodes are free (advertised by agent), and
        update the DB accordingly.  If ignorenew is True, this will only
        make sure that the data in the DB is correct, and not complete.
        If ignorenew is False (the default), this will do a complete
        update of the DB.  However, this can take some time, as
        information about new nodes (such as link type) must be
        discovered.  Plab nodes that are in the DB but are not available
        are marked as status down.

        Note that this seemingly innocent funciton actually does a lot of
        magic.  This is the main/only way that Plab nodes get into the
        nodes DB, and this list is updated dynamically.  It also gathers
        static data about new nodes.

        Deleting nodes that are no longer available may not be the best
        approach, due to the overhead of adding new nodes (ie, if the
        node disappears for a while, then comes back), but the agent's
        advertisement list doesn't change very dynamically (basically,
        it's a list of the nodes reporting to ganglia that they support
        dslices)
        """
        print "Getting free Plab nodes ..."
        try:
            agent = self._createAgentProxy(insecure = True)
            avail = tryXmlrpcCmd(agent.getads)
        except:
            extype, exval, extrace = sys.exc_info()
            print "Error talking to dslice agent: %s: %s" % (extype, exval)
            if debug:
                print extrace
            print "Going back to sleep until next scheduled poll"
            return

        if debug:
            print "Got advertisement list:"
            print avail

# pinging disabled for now since many sites block ICMP
#        if debug:
#            print "Pinging nodes in advertisement list"
#        avail = self.__getPingStatus(avail)
#        if debug:
#            print "Refined node list after ping verification:"
#            print avail

        known = self.__getKnownPnodes()
        if debug:
            print "Got known pnodes:"
            print known

        # Mark known nodes that are not available as down and make sure
        # those that are available are marked as up
        todown = []  # List of nodeid's
        toup = []  # List of nodeid's
        for ip in known.keys():
            if not ip in avail:
                todown.append(known[ip])
            else:
                toup.append(known[ip])
        if verbose:
            print "%d known Plab nodes not available" % len(todown)
            print "%d known Plab nodes available" % len(toup)
        self.__setVnodesStatus(todown, "down")
        self.__setPnodesStatus(todown, "down")
        self.__setVnodesStatus(toup, "up")
        self.__setPnodesStatus(toup, "up")

        # Add new nodes
        toadd = []  # List of IP's
        for ip in avail:
            if not known.has_key(ip):
                if len(ALLOWED_NODES) and not ip in ALLOWED_NODES:
                    if verbose:
                        print "Skipping %s because it's not in the allowed" \
                              " list" % ip
                    continue
                toadd.append(ip)
        if len(toadd):
            if ignorenew:
                if verbose:
                    print "%d new Plab nodes, but ignored for now" % len(toadd)
            else:
                print "There are %d new Plab nodes." % len(toadd)
                for ip in toadd:
                    linktype, hostname = self.__findLinkType(ip)
                    if debug:
                        print "Found linktype %s for node %s" % (linktype, ip)
                    self.__addNode(ip, linktype, hostname)

                print "Forcing a named map update ..."
                os.spawnl(os.P_WAIT, NAMED_SETUP, NAMED_SETUP)
                print "Done adding new Plab nodes."

    def __getKnownPnodes(self):
        """
        getFree helper function.  Returns a dict of IP:node_id pairs
        for the Plab nodes that currently exist in the DB.
        """
        res = DBQueryFatal("select i.node_id, i.IP from interfaces as i"
                           " left join nodes as np on"
                           "  np.node_id = i.node_id"
                           " where np.type = 'pcplabphys'")
        ret = {}
        for nodeid, ip in res:
            ret[ip] = nodeid
        return ret

    def __getPingStatus(self, ips):
        """
        getFree helper function.  Uses fping to test the reachability of
        the PLAB nodes returned from the dslice agent.  If a node doesn't
        respond, it is not returned (i.e., not available)
        """
        from socket import inet_aton
        fpin, fpout = os.popen2("fping -aA")
        fpin.write("\n".join(ips))
        fpin.close()
        results = fpout.read().split()
        # Get rid of potential junk in output
        for ip in results:
            try:
                inet_aton(ip)
            except:
                if verbose:
                    print "Removing junk from fping output:"
                    print "\t%s" % ip
                results.remove(ip)
        return results
        
    def __setVnodesStatus(self, pnodeids, status):
        """
        getFree helper function.  Sets the status of all vnodes that are
        in state SHUTDOWN with a phys_nodeid from the given list.  Those
        that are not in state SHUTDOWN should have a watchdog running, so
        they don't need to be propped up.
        """
        if not len(pnodeids):
            return
        if debug:
            print "Setting status to %s for vnodes of %s" % (status, pnodeids)
        # Unfortunately, this query has to join nodes and node_status,
        # which means it can't all be done with a single update (until
        # we upgrade to MySQL 4.0.4 at least :)
        clause = ", ".join(["%s"] * len(pnodeids))
        res = DBQueryFatal("select node_id from nodes"
                           " where eventstate = 'SHUTDOWN'"
                           " and phys_nodeid in (" + clause + ")",
                           pnodeids)
        if len(res):
            vnodeids = map(lambda x: x[0], res)
            clause = ", ".join(["%s"] * len(vnodeids))
            DBQueryFatal("update node_status set status = %s,"
                         " status_timestamp = now()"
                         " where node_id in (" + clause + ")",
                         [status] + list(vnodeids))

    def __setPnodesStatus(self, pnodeids, status):
        """
        getFree helper function.  Sets the status of all pnodes with a
        node_id in the given list.
        """
        if not len(pnodeids):
            return
        if debug:
            print "Setting status to %s for pnodes %s" % (status, pnodeids)
        clause = ", ".join(["%s"] * len(pnodeids))
        DBQueryFatal("update node_status set status = %s,"
                     " status_timestamp = now()"
                     " where node_id in (" + clause + ")",
                     [status] + list(pnodeids))

    def __findLinkType(self, ip):
        """
        getFree helper function.  Figures out the link type of the given
        host.  This first performs a traceroute and checks for the U of
        U's I2 gateway to classify Internet2 hosts.  If this test fails,
        it checks if the hostname is international.  If this test fails,
        this simply specifies an inet link type.

        This can't detect DSL links, but those are probably rare for
        Plab nodes.
        """
        # Is host international (or flux/emulab local)?
        from socket import gethostbyaddr, getfqdn, herror
        hostname = ip
        try:
            hostname, aliaslist, ipaddrlist = gethostbyaddr(ip)
            hostname = getfqdn(hostname)
            tld = hostname.split(".")[-1].lower()
            if not tld in ("edu", "org", "net", "com", "gov", "us", "ca"):
                return "pcplabintl", hostname
            
            # Is it us?
            if hostname.endswith(LOCAL_PLAB_DOMAIN):
                return LOCAL_PLAB_LINKTYPE, hostname
            
        except herror:
            hostname = ip
            print "WARNING: Failed to get hostname for %s" % ip

        # Is host on I2?
        traceroute = os.popen("traceroute -nm 10 -q 1 %s" % ip)
        trace = traceroute.read()
        traceroute.close()

        for gw in MAGIC_INET2_GATEWAYS:
            if trace.find(gw) != -1:
                return "pcplabinet2", hostname

        for gw in MAGIC_INET_GATEWAYS:
            if trace.find(gw) != -1:
                break
        else:
            print "WARNING: Unknown gateway for host %s" % ip

        # Must be plain 'ole Internet
        return "pcplabinet", hostname

    def __addNode(self, ip, linktype, hostname):
        """
        getFree helper function.  Adds a new Plab pnode and associated
        vnodes to the DB.  linktype should be one of (inet2, inet, intl,
        dsl).

        XXX This duplicates a lot of the functionality of newwanode.
        Note that, very unlike newwanode, the node is initially up,
        since it had to be up to be added in the first place.  This also
        adds some additional fields that newwanode doesn't, and takes
        advantage of the fact that the Plab nodes may be added in bulk.
        """
        # block out common termination signals while adding a node
        osigs = disable_sigs(TERMSIGS)
        defosid, controliface = self.__getNodetypeInfo()
        id, priority = self.__nextFreeNodeid()
        nodeid = "plab%d" % id
        hostname = string.replace(hostname, ".", "-")
        print "Creating pnode %s as %s, priority %d." % (ip, nodeid, priority)

        try:
            DBQueryFatal("insert into nodes"
                         " (node_id, type, phys_nodeid, role, priority,"
                         "  op_mode, def_boot_osid,"
                         "  allocstate, allocstate_timestamp,"
                         "  eventstate, state_timestamp)"
                         " values (%s, %s, %s, %s, %s,"
                         "  %s, %s, %s, now(), %s, now())",
                         (nodeid, 'pcplabphys', nodeid,
                          'testnode', priority*100,
                          'ALWAYSUP', defosid,
                          'FREE_CLEAN',
                          'ISUP'))

            DBQueryFatal("insert into interfaces"
                         " (node_id, card, port, IP, interface_type,"
                         " iface, role)"
                         " values (%s, %s, %s, %s, %s, %s, %s)",
                         (nodeid, 0, 1, ip, 'fxp', controliface, 'ctrl'))

            DBQueryFatal("insert into reserved"
                         " (node_id, pid, eid, rsrv_time, vname)"
                         " values (%s, %s, %s, now(), %s)",
                         (nodeid, RESERVED_PID, RESERVED_EID, hostname))

            DBQueryFatal("insert into node_auxtypes"
                         " (node_id, type, count)"
                         " values (%s, %s, %s)",
                         (nodeid, linktype, 1))
            
            DBQueryFatal("insert into node_status"
                         " (node_id, status, status_timestamp)"
                         " values (%s, %s, now())",
                         (nodeid, 'up'))

            vnodetype = "pcplab"
            vnodeid = ""
            for n in range(NUMVNODES):
                vprio = (priority * 100) + (n+1)
                sshdport = 38000+(n+1)
                vnodeid = "%s-%d" % (nodeid, n+1)
                if verbose:
                    print "Creating vnode %s, priority %d" % (vnodeid, vprio)
                    
                DBQueryFatal("insert into nodes"
                             " (node_id, type, phys_nodeid, role, priority,"
                             "  op_mode, def_boot_osid, update_accounts,"
                             "  allocstate, allocstate_timestamp,"
                             "  eventstate, state_timestamp, sshdport)"
                             " values (%s, %s, %s, %s, %s,"
                             "  %s, %s, %s, %s, now(), %s, now(), %s)",
                             (vnodeid, vnodetype, nodeid, 'virtnode', vprio,
                              'PCVM', defosid, 1,
                              'FREE_CLEAN',
                              'SHUTDOWN', sshdport))
                
                DBQueryFatal("insert into node_status"
                             " (node_id, status, status_timestamp)"
                             " values (%s, %s, now())",
                             (vnodeid, 'up'))
                
            # Now, put the last vnode created into the special monitoring expt.
            DBQueryFatal("insert into reserved"
                         " (node_id, pid, eid, rsrv_time, vname)"
                         " values (%s, %s, %s, now(), %s)",
                         (vnodeid, MONITOR_PID, MONITOR_EID, vnodeid))
            
        except:
            print "Error adding PLAB node to DB: someone needs to clean up!"
            tbmsg = "".join(traceback.format_exception(*sys.exc_info()))
            SENDMAIL(TBOPS, "Error adding new plab node to DB: %s\n" %
                     nodeid, "Some operation failed while trying to add a"
                     " newly discovered plab node to the DB:\n %s"
                     "\n Please clean up!\n" % tbmsg)
            enable_sigs(osigs)
            raise

        # last but not least, unblock signals
        enable_sigs(osigs)

    def __getNodetypeInfo(self):
        """
        addNode helper function.  Returns a (defosid, controliface) 
        tuple for the Plab pnode type.  Caches the result since
        it doesn't change.
        """
        if not hasattr(self, "__getNodetypeInfoCache"):
            if debug:
                print "Getting node type info"
            res = DBQueryFatal("select osid, control_iface"
                               " from node_types"
                               " where type = 'pcplabphys'")
            assert (len(res) == 1), "Failed to get node type info"
            (self.__getNodetypeInfoCache, ) = res

        return self.__getNodetypeInfoCache

    def __nextFreeNodeid(self):
        """
        addNode helper function.  Returns a (nodeid, priority) tuple of
        the next free nodeid and priority for Plab nodes.
        """
        if debug:
            print "Getting next free nodeid"
        DBQueryFatal("lock tables nextfreenode write")
        try:
            res = DBQueryFatal("select nextid, nextpri from nextfreenode"
                               " where nodetype = 'pcplab'")
            assert (len(res) == 1), "Unable to find next free nodeid"
            DBQueryFatal("update nextfreenode"
                         " set nextid = nextid + 1, nextpri = nextpri + 1"
                         " where nodetype = 'pcplab'")
            ((nodeid, priority), ) = res
        finally:
            print "Getting/updating next free nodeid for plab failed!"
            DBQueryFatal("unlock tables")
        return nodeid, priority

    def renew(self):
        """
        Renews all of the Plab leases that are going to expire soon.
        """
        print "Renewing Plab leases ..."
        # Ugh, MySQL doesn't know UTC until v4.1.1, and unix_timestamp()
        # returns the local time
        import time
        endtime = int(time.mktime(time.gmtime())) + RENEW_TIME
        res = DBQueryFatal("select pid, eid, node_id from plab_slice_nodes"
                           " where %s > unix_timestamp(leaseend)",
                           (endtime, ))
        loadedSlices = {}
        for pid, eid, nodeid in res:
            try:
                slice = loadedSlices[(pid, eid)]
            except KeyError:
                slice = self.loadSlice(pid, eid)
                loadedSlices[(pid, eid)] = slice
            node = slice.loadNode(nodeid)
            node.renew()

    def _createAgentProxy(self, insecure = False):
        """
        Creates an agent proxy connected to the Plab central agent.
        Also caches the agent for later reuse.
        """
        if not self.__agentProxy:
            if verbose:
                print "Connecting to agent %s" % AGENTIP
            if insecure:
                args = (AGENTIP, agent.PORT)
            else:
                args = (AGENTIP, agent.PORT, agent.SSLPORT,
                        self.keyfile, self.certfile, self.cacertfile)
            self.__agentProxy = agentproxy.agentproxy(*args)
        return self.__agentProxy


#
# Slice abstraction
#

class Slice:
    def __init__(self, plab, pid, eid):
        self.plab = plab
        self.pid, self.eid = pid, eid
    
    def _create(self):
        """
        Creates a new slice that initially contains no nodes.  Don't call
        this directly, use Plab.createSlice instead.
        """
        res = DBQueryFatal("select idx from experiments "
                              "where pid=%s "
                              "and eid=%s",
                              (self.pid, self.eid))
        if not len(res):
            raise RuntimeError, "Didn't get any results while looking for idx"
        eindex = res[0][0]
        self.slicename = "emulab_%s" % eindex
        print "Creating Plab slice %s." % self.slicename
        self.privkey, self.pubkey = self.__genKeypair()
        try:
            DBQueryFatal("insert into plab_slices"
                         " (pid, eid, slicename, privkey, pubkey) "
                         " values (%s, %s, %s, %s, %s)",
                         (self.pid, self.eid, self.slicename,
                          self.privkey, self.pubkey))
        except:
            # No cleanup necessary
            raise
        # It turns out that there's no concrete "slice" in dslice, so
        # nothing real needs to be done

    def _load(self):
        """
        Loads an already allocated slice from the DB.  Don't call this
        directly, use Plab.loadSlice instead.

        XXX This should probably be made lazy, since not all operations
        really need it
        """
        if verbose:
            print "Loading slice for pid/eid %s/%s" % (self.pid, self.eid)
        res = DBQueryFatal("select slicename, privkey, pubkey from plab_slices"
                           " where pid = %s and eid = %s",
                           (self.pid, self.eid))
        assert (len(res) > 0), \
               "No slice found for %s-%s" % (self.pid, self.eid)
        assert (len(res) == 1), \
               "Multiple slices found for %s-%s" % (self.pid, self.eid)
        ((self.slicename, self.privkey, self.pubkey), ) = res

    def destroy(self):
        """
        Frees all nodes in this slice and destroys the slice.  Note
        that this will really pound the DB if there are many nodes left
        in the slice, but those should be removed by Emulab before the
        slice is destroyed.
        """
        print "Destroying Plab slice %s." % self.slicename
        res = DBQueryFatal("select node_id from plab_slice_nodes"
                           " where slicename = %s",
                           (self.slicename))
        print "\tRemoving any remaining nodes in slice.."
        for (nodeid,) in res:
            node = self.loadNode(nodeid)
            node.free()
            del node  # Encourage the GC'er

        print "\tRemoving slice DB entry."
        osigs = disable_sigs(TERMSIGS)
        try:
            DBQueryFatal("delete from plab_slices where slicename = %s",
                         (self.slicename,))
        except:
            print "Error deleting slice from DB!"
            tbstr = "".join(traceback.format_exception(*sys.exc_info()))
            SENDMAIL(TBOPS, "Error deleting slice from DB",
                     "Slice deletion error:\n\n%s" % tbstr)
            enable_sigs(osigs)
            raise
        
        enable_sigs(osigs)

    def createNode(self, nodeid):
        """
        Node factory function
        """
        node = Node(self, nodeid)
        node._create()
        return node

    def loadNode(self, nodeid):
        """
        Node factory function
        """
        node = Node(self, nodeid)
        node._load()
        return node

    def __genKeypair(self):
        """
        Generates a passphrase-less RSA keypair and returns the PEM
        format data to be stored in the slice's identity and
        identity.pub files.
        """
        # XXX This is a workaround for a bug in M2Crypto
        import tempfile

        if verbose:
            print "Generating slice keypair"
        # pdssi = Plab Dynamic Slice SSH Identity
        fname = tempfile.mktemp("pdssi%d" % os.getpid())
        if debug:
            print "Writing keypair to %s(.pub)" % fname
        if os.spawnlp(os.P_WAIT, "ssh-keygen",
                      "ssh-keygen", "-t", "rsa", "-b", "1024", "-P", "",
                      "-f", fname, "-q"):
            raise RuntimeError, "Error generating slice keypair"
        
        privkey = file(fname, "rb").read()
        pubkey = file(fname + ".pub", "rb").read()
        map(os.unlink, (fname, fname + ".pub"))
        
        return privkey, pubkey
        
        
        # Below here is the way it _should_ be done
        if verbose:
            print "Generating slice keypair"
        key = RSA.gen_key(1024, 35)    # OpenSSH ssh-keygen uses 35 for e

        privkeyio = cStringIO.StringIO()
        # Due to a current bug in M2Crypto, None cannot be passed as the
        # cipher; therefore, passphraseless keys cannot be generated
        key.save_key_bio(BIO.File(privkeyio), None)
        privkey = privkeyio.getvalue()

        pubkeyio = cStringIO.StringIO()
        key.save_pub_key_bio(BIO.File(pubkeyio))
        pubkey = pubkeyio.getvalue()

        return privkey, pubkey

#
# Node abstraction
#

class Node:
    def __init__(self, slice, nodeid):
        self.slice, self.plab = slice, slice.plab
        self.nodeid = nodeid
        self.ip = self.__findIP()
        self.__nodemgrProxy = None

    # XXX: may want to rethink signal handling here.
    def _create(self):
        """
        Creates a new node.  This physically allocates the node into the
        slice through the dslice agent and node manager.  Note that no
        node setup is performed.  Don't call this directly, use
        Slice.createNode instead.
        """
        
        # First, make sure there isn't already an entry in the DB
        try:
            self._load()
        except:
            pass
        else:
            raise RuntimeError, "Entry for plab node %s already exists " \
                  "in the DB" % self.nodeid

        # Now get a ticket, and redeem it for a vm lease
        print "Creating Plab node %s on %s." % (self.nodeid, self.ip)
        agent = self.plab._createAgentProxy()
        tickets = tryXmlrpcCmd(agent.newtickets,
                               (self.slice.slicename, 1, LEASELEN, (self.ip,)))
        assert (len(tickets) == 1), "%d tickets returned" % len(tickets)
        self.ticketdata = tickets[0]
        if debug:
            print "Obtained ticket:"
            print self.ticketdata

        nodemgr = self._createNodemgrProxy()
        self.leasedata = None
        
        tries = DEF_TRIES
        while 1:
            try:
                self.leasedata = tryXmlrpcCmd(nodemgr.newleasevm,
                                              (self.ticketdata,
                                               self.slice.privkey,
                                               self.slice.pubkey),
                                              inittries = tries,
                                              raisefault = True)

            # We may have actually gotten the lease/vm even though
            # the xmlrpc call appeared to fail.  We check for this
            # condition here, which will show up on subsequent allocation
            # attempts.
            except xmlrpclib.Fault, e:
                if e.faultString.find("already exists") != -1:
                    print "Lease for %s already exists!" % self.nodeid
                    nodeleases = tryXmlrpcCmd(nodemgr.getleases)
                    for mylease in nodeleases:
                        if mylease.find(self.slice.slicename) != -1:
                            self.leasedata = mylease
                            break
                    else:
                        raise RuntimeError, "Whoop!  Couldn't find my lease " \
                              "even though it was supposed to be present!"
                    break
                elif e.triesleft > 0:
                    tries = e.triesleft
                else:
                    raise
            # success
            else:
                break

        # Good, we have a lease; now put an entry into the DB
        if debug:
            print "Obtained lease/vm:"
            print self.leasedata
        self.lease = lease.lease(self.leasedata)
        # Note that the lease's end_time happens to be formatted the
        # same as a SQL DATETIME (how conspicuously convenient...)
        DBQueryFatal("insert into plab_slice_nodes"
                     " (pid, eid, slicename, node_id,"
                     " ticketdata, leasedata, leaseend)"
                     " values (%s, %s, %s, %s, %s, %s, %s)",
                     (self.slice.pid, self.slice.eid,
                      self.slice.slicename, self.nodeid,
                      self.ticketdata, self.leasedata,
                      self.lease.end_time))


    def _load(self):
        """
        Loads an already allocated node from the DB.  Don't call this
        directly, use Slice.loadNode instead.
        """
        if verbose:
            print "Loading node %s" % self.nodeid
        res = DBQueryFatal("select slicename, ticketdata, leasedata"
                           " from plab_slice_nodes where node_id = %s",
                           (self.nodeid))
        assert (len(res) > 0), \
               "Node %s (slice %s) not found" % \
               (self.nodeid, self.slice.slicename)
        assert (len(res) == 1), \
               "Multiple nodes found for nodeid %s" % self.nodeid
        ((slicename, self.ticketdata, self.leasedata), ) = res
        assert (slicename == self.slice.slicename), \
               "Node %s loaded by slice %s, but claims to be in slice %s" % \
               (self.nodeid, self.slice.slicename, slicename)
        self.lease = lease.lease(self.leasedata)

    def free(self):
        """
        Frees the node and kills the VM.  Note that this does not
        shutdown anything inside the vserver.  Warning: forks a process
        to carry out the actual work!
        """
        ForkCmd(self._free, timeout=FREE_TIMEOUT,
                disable_sigs_parent=TERMSIGS, disable_sigs_child=TERMSIGS)
        
    def _free(self):
        """
        Frees the node and kills the VM.  Note that this does not
        shutdown anything inside the vserver.  Don't call this directly;
        instead, use Node.free()
        """
        ret = None
        deleted = 0

        print "Freeing Plab node %s." % self.nodeid
        
        # Get node manager handle
        nodemgr = self._createNodemgrProxy()

        # Remove the DB entry first.
        try:
            DBQueryFatal("delete from plab_slice_nodes where node_id = %s",
                         (self.nodeid,))
        except:
            print "Uh oh, couldn't remove plab sliver record from the DB!"
            tbstr = "".join(traceback.format_exception(*sys.exc_info()))
            SENDMAIL(TBOPS, "Error: Couldn't remove plab vnode from DB",
                     "Unable to delete entry for sliver %s from the DB:"
                     "\n\n%s" % (self.nodeid, tbstr))

        tries = DEF_TRIES
        while 1:
            try:
                ret = tryXmlrpcCmd(nodemgr.deletelease, self.slice.slicename,
                                   inittries = tries, raisefault = 1)
            except xmlrpclib.Fault, e:
                if e.faultString.find("does not exist") != -1:
                    print "Lease for %s did not exist on node" % self.nodeid
                    deleted = 1
                    break
                elif e.triesleft > 0:
                    tries = e.triesleft
                else:
                    break
            except:
                print "Warning: couldn't delete the lease for %s on %s" % \
                      (self.slice.slicename, self.nodeid)
                tbstr = "".join(traceback.format_exception(*sys.exc_info()))
                SENDMAIL(TBOPS, "Sliver lease deletion failed on %s, "
                         "dslice %s" % (self.nodeid, self.slice.slicename),
                         "Sliver lease deletion failed:\n\n%s" % tbstr)
                break
            else:
                deleted = 1
                break

        if deleted and debug:
            print "Deleted lease/VM: %s" % `ret`

        return ret

    def addKey(self, identityfile):
        """
        Adds an ssh public key to the node.  Note that identityfile must
        be the path of the public key.  This must be done before any
        calls to becomeEmulba, addtoGroup, or unpackTgz, because those
        commands rely on ssh'ing into the node.  Note also that this
        should be one of the keys that ssh naturally knows about, or
        those commands will fail.
        """
        if verbose:
            print "Adding pubkey to node %s" % self.nodeid
        if not identityfile.endswith(".pub"):
            raise RuntimeError, "File %s doesn't look like a pubkey" % \
                  identityfile
        pubkey = file(identityfile, "rb").read().strip()
        nodemgr = self._createNodemgrProxy()
        ret = tryXmlrpcCmd(nodemgr.addkey, (self.slice.slicename, pubkey))
        if debug:
            print "Added key: %s" % `ret`
        return ret

    def renew(self):
        """
        Renew the lease for this node.  Note that this method
        forks and runs another private method to actually do the
        work!
        """
        ForkCmd(node.renew, timeout = RENEW_TIMEOUT,
                disable_sigs_parent = TERMSIGS)

    def _renew(self):
        """
        Renew the lease for node belonging to this instance.  Don't
        call this directly; instead, use Node.renew()
        """
        print "Renewing lease on Plab node %s." % self.nodeid
        nodemgr = self._createNodemgrProxy()

        tries = DEF_TRIES
        while 1:
            try:
                self.leasedata = tryXmlrpcCmd(nodemgr.renewlease,
                                              self.slice.slicename,
                                              inittries = tries,
                                              raisefault = True)
            except xmlrpclib.Fault, e:
                if e.faultString.find("does not exist") != -1:
                    print "No lease found on %s for slice %s" % \
                          (self.nodeid, self.slice.slicename)
                    return
                elif e.triesleft > 0:
                    tries = e.triesleft
                else:
                    raise                    
        if debug:
            print "Obtained new lease:"
            print self.leasedata
        self.lease = lease.lease(self.leasedata)
        DBQueryFatal("update plab_slice_nodes"
                     " set leasedata = %s, leaseend = %s",
                     (self.leasedata, self.lease.end_time))

    def emulabify(self, rootballpath = DEFAULT_DATA_PATH,
                  rootballname = DEF_ROOTBALL_NAME):
        """
        Performs the necessary steps to turn this node into an
        Emulab/Plab node.  Primarily, this unpacks the magic files on to
        the node.
        """
        print "Overlaying Emulab files on %s ..." % self.nodeid
        self.__copy(DEFAULT_DATA_PATH + "fixsudo.sh", "/tmp/fixsudo.sh")
        self.__perform("-tt sh /tmp/fixsudo.sh")
        self.addToGroup(self.slice.slicename, "root")
        self.unpackTgz(rootballpath, rootballname)

    def addToGroup(self, user, group):
        if verbose:
            print "Adding %s to group %s on node %s" % \
                  (user, group, self.nodeid)
        self.__perform("sudo /usr/sbin/usermod -G %s %s" % (group, user))

    def unpackTgz(self, tgzpath, tgzname, destpath = "/"):
        """
        Unpacks a locally stored gzip'd tarball to the specified path
        (default /) on the remote node.  Always done as remote root.
        """
        if verbose:
            print "Unpacking tgz %s to %s on %s" % \
                  (tgzpath, destpath, self.nodeid)
        try:
            if debug:
                print "Trying to grab rootball through loopback service"
            self.__perform("sudo wget -q -nH -P /tmp " +
                           ROOTBALL_HTTP_URLPATH + tgzname)
        except RuntimeError:
            print "Warning: couldn't get tarball via local service on %s: " \
                  "Falling back to remote transfer." % self.nodeid
            self.__copy(tgzpath + tgzname, "/tmp/" + tgzname)
            
        self.__perform("sudo tar -xzf /tmp/" + tgzname + " -C %s" % destpath)

    def __perform(self, command):
        """
        Executes the given command on the remote node via sshtb
        """
        if debug:
            print "Performing '%s' on %s" % (command, self.nodeid)
        if os.spawnl(os.P_WAIT, SSH, SSH, "-host", self.nodeid, command):
            raise RuntimeError, "ssh '%s' failed" % command

    def __copy(self, localfile, remotefile):
        """
        Copies a file from the local system to the remote node, doing so
        as root.
        """
        if debug:
            print "Copying %s to %s on %s" % \
                  (localfile, remotefile, self.nodeid)
        # dd is a bit overbearing for this job, but I can't do something
        # simply like an scp (because the I can't get remote root), or a
        # cat with a redirect (because sshtb munges the redirect and
        # winds up evaluating it in a local shell)
        if os.system("%s -host %s 'dd of=%s' < '%s' > /dev/null 2>&1" %
                     (SSH, self.nodeid, remotefile, localfile)):
            raise RuntimeError, "Copying %s to %s failed" % \
                  (localfile, remotefile)

    def __findIP(self):
        """
        Figures out and returns the IP of the remote node.
        """
        res = DBQueryFatal("select i.IP from interfaces as i"
                           " left join nodes as nv on"
                           "  i.node_id=nv.phys_nodeid"
                           " where nv.node_id=%s"
                           " limit 1",
                           (self.nodeid))
        assert (len(res) > 0), \
               "No IP found for nodeid %s" % self.nodeid
        ((ip, ), ) = res
        if debug:
            print "Found IP %s for node %s" % (ip, self.nodeid)
        return ip

    def _createNodemgrProxy(self):
        """
        Creates a node manager proxy connected to this node's node
        manager.  Also caches the nodemgr for later reuse.
        """
        if not self.__nodemgrProxy:
            if verbose:
                print "Connecting to nodemgr for %s on %s" % \
                      (self.nodeid, self.ip)
            self.__nodemgrProxy = \
                                nodemgrproxy.nodemgrproxy(self.ip,
                                                          nodemgr.PORT,
                                                          nodemgr.SSLPORT,
                                                          self.plab.keyfile,
                                                          self.plab.certfile,
                                                          self.plab.cacertfile)
        return self.__nodemgrProxy
