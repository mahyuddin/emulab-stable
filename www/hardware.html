<!--
   EMULAB-COPYRIGHT
   Copyright (c) 2000-2003, 2005, 2006 University of Utah and the Flux Group.
   All rights reserved.
  -->
<center>
<h1>
    Hardware Overview, "Emulab Classic"
</h1>
</center>

<h3>Test Nodes</h3>
<ul>
<a name="tbpcs"></a>
<ul>

<a name="tbpc3000"></a>
<li>160 <a href=shownodetype.php3?node_type=pc3000>pc3000</a>
	PC nodes (<b>pc201-pc360</b>) consisting of:
<ul>
<li> 3.0 GHz 64-bit Xeon processors, 800Mhz FSB
<li> Based on the
     <a href =
     "http://www.dell.com/downloads/global/products/pedge/en/2850_specs.pdf">
      Dell Poweredge 2850</a>
<li> 2GB 400Mhz DDR2 RAM
<li> Multiple PCI-X 64/133 and 64/100 busses
<li> 6 10/100/1000 Intel NICs spread across the busses
	(one NIC is the control net). 
	<a href=doc/docwrapper.php3?docname=pc3000.html>
	  <b>Important Notes</b>.<a>
<li> 2 x 146GB 10,000 RPM SCSI disks
</ul>
<p>

<a name="tbpc850"></a>
<li>128 <a href=shownodetype.php3?node_type=pc850>pc850</a>
             PC nodes (<b>pc41-pc168</b>), consisting of:
<ul>
<li> 850MHz Intel Pentium III processors.
<li> Based on the
<a
href="http://www.intel.com/support/motherboards/server/isp1100/">
Intel ISP1100 </a> 1U server platform (old reliable BX chipset).
<li> 512MB PC133 ECC SDRAM.
<li> 5
<a
href="http://support.intel.com/support/network/adapter/pro100/index.htm">
Intel EtherExpress Pro</a> 10/100Mbps Ethernet ports:
<ul>
	<li>2 builtin on the motherboard
		(<code>eth2/eth3</code> in Linux, <code>fxp0/fxp1</code> in FreeBSD)</i>
	<li>2 on an
	    <a href = "http://www.intel.com/network/connectivity/resources/doc_library/tech_specs/pro100dport.htm">
	    Intel EtherExpress Pro 100+ Dual-Port Server Adapter</a>
		(<code>eth0/eth1</code> in Linux, <code>fxp2/fxp3</code> in FreeBSD)
	<li>1 on a single-port Intel EtherExpress Pro/100B Adapter
		(<code>eth4</code> in Linux, <code>fxp4</code> in FreeBSD)
</ul>
<li> 
40GB IBM 60GXP 7200RPM ATA/100 IDE hard drive.
<li> Floppy drive.
</ul>
<p>

<a name="tbpc600"></a>
<li>40 <a href=shownodetype.php3?node_type=pc600>pc600</a>
        PC nodes (<b>pc1-40</b>), consisting of:

<ul>
<li> 600MHz Intel Pentium III "Coppermine" processors.
<li> 
Asus P3B-F (6 PCI/1 ISA slot) motherboard (old reliable BX chipset).
<li> 256MB PC100 ECC SDRAM.
<li> 5
<a
href="http://support.intel.com/support/network/adapter/pro100/index.htm">
Intel EtherExpress Pro/100B</a> 10/100Mbps Ethernet cards.
<li>
13GB IBM 34GXP DPTA-371360 7200RPM IDE hard drive.
<li> Floppy drive
<li> Cheap video card (Jaton Riva 128ZX AGP w/4MB video RAM)
<li> All in a nice but overweight rackmount case on rails:
Antec IPC3480B, with 300W PS and extra fan.
</ul>
<p>

<a name="tbpc3000w"></a>
<li>18 <a href=shownodetype.php3?node_type=pc3000w>pc3000w</a>
        wireless PC nodes (<b>pcwf1-18</b>), consisting of:
<ul>
<li> 3.0GHz Intel Pentium 4 processors.
<li> 1GB DDR-400MHz (PC3200) SDRAM.
<li> 2 <a href="http://netgear.com/products/details/WAG311.php">Netgear WAG311
802.11a/b/g</a> (Atheros) wifi cards.
<li> 2 Ethernet ports:
<ul>
	<li>1 <a href="http://support.intel.com/support/network/adapter/index.htm">Intel
	Pro 1000</a> 10/100/1000Mbps builtin on the motherboard.
	<li>1 <a
	href="http://support.intel.com/support/network/adapter/pro100/index.htm">Intel
	EtherExpress Pro/100 S</a> 10/100Mbps Ethernet card.
</ul>
<li> 2 Western Digital WDXL80 120GB 7200RPM Serial ATA hard drives.
<li> Floppy and CD-ROM drive.
</ul>
<p>

<a name="tbpc2000"></a>
<li>8 <a href=shownodetype.php3?node_type=pc2000>pc2000</a>
	PC nodes (<b>pc170-pc178</b>) consisting of:
<ul>
<li> 2.0 GHz Pentium IV processors, 400Mhz FSB
<li> Based on the Dell Precision WorkStation 340
<li> 512MB 400Mhz RAMBUS RAM
<li> 5 10/100 Intel NICs (one NIC is the control net). 
<li> <a href="http://www.emulab.net/tutorial/docwrapper.php3?docname=ixp.html">
     Intel IXP 1200 network processor cards</a>.
<li> 2 x 20GB 7200 RPM IDE disks
</ul>

</ul>
<h3>Servers</h3>
<ul>

<li> a users, file, and serial line server (<b>users.emulab.net</b>), consisting of:

<ul>
<li> Dual 500MHz Intel Pentium III processors
<li> 
Intel L440GX+ motherboard (the GX+ chipset)
<li> 512MB PC100 ECC SDRAM
<li> 90 GB disk space: 5 
Quantum Atlas IV 18GB 7200RPM Wide LVD SCSI hard drives
</ul>
<p>

<li> a DB, web, DNS and operations server, consisting of:

<ul>
<li>
Dell PowerEdge 2550 Rack Mount Server
<li> Single 1000MHz Intel Pentium III processor
<li> 512MB PC133 ECC SDRAM
<li> Dual-Channel On-board RAID (5) Controller 128MB Cache (2-Int Channels)
<li> Five 18GB Ultra3 (Ultra160) SCSI 10K RPM Hot Plug Hard Drives
<li> Dual Redundant 330 Watt Power Supplies
<li> Integrated Broadcom Gigabit BaseT and Intel Pro/100+ NICs
</ul>
<p>

<li> a motley collection of serial line servers, consisting of:
<ul>
<li> a 2U home brew box (our old "ops" node) with
     3 64-port
     <a href="http://www.cyclades.com/products/svrbas/zseries.htm">
     Cyclades-Ze PCI Multiport Serial Boards</a> (model number SEZ0050).
<li> 1U box from <a href = "http://www.asacomputers.com/">ASA Computers</a>
     with another 64-port Cyclades-Ze PCI Multiport Serial Board.
<li> 2 Dell OptiPlex GX240s with a total of 6 <a
	href="http://www.comtrol.com/products/hardware/rp_upci.asp">
	32-port RocketPort Universal PCI interfaces</a>.
<li> a serial line server for critical Emulab machines, consisting of
	an ISP1100 box, like the "pc850" nodes above with a 4-port Cyclades
	card.
</ul>
<p>

</ul>
<h3>Switches and Routers</h3>
<ul>

<li> 7
    <a href=http://www.cisco.com/warp/public/cc/pd/si/casi/ca6000/index.shtml> 
    Cisco 6500 series high-end switches</a>. Five serve as the
    <a name="tbbackplane"></a>
    <a href=doc/docwrapper.php3?docname=topo.html>testbed backplane</a>
    ("programmable patch panel").<br>
        The other two, a 6506 and 6509
	providing "control" interfaces for the test nodes with
        the 6509 hosting an MSFC router card and functioning as the
	<a name="tbcorerouter"></a>
	<em>core router</em> for the testbed,
	regulating access to the testbed servers and the outside world.
	<br>
<p>

</ul>
<h3>Power Controllers</h3>
<ul>

<li>10 APC MasterSwitch AP9210 8 port power controllers.<br>
    (The AP9210 is discontinued; replaced in the product line by the
    AP9211.)
<p>
<li>7 <a href="http://www.baytechdcd.com/products/prodlist.php?show=RPC27">
	BayTech RPC27</a> 20-port remote power controllers.<br>
<p>
<li>24 <a href="http://www.baytechdcd.com/products/prodlist.php?show=RPC14">
	BayTech RPC14</a> 1U 8-port remote power controllers.<br>
</ul>
<h3>Racks</h3>
<ul>

<li>13
	Wrightline "Tech I" racks: 44U, 34" deep, 2 are
	24" wide with cable management; the rest are 19" wide.
	(Aug 2001: these appear to have been discontinued or renamed.)
<p>

</ul>

<p><h2>Layout</h2><p>

Four ethernet ports on each PC node are connected to the
      <a href="#tbbackplane">testbed backplane</a>.
      All of the over 1300 ports can be connected in arbitrary ways by setting up VLANs
      on the switches via remote configuration tools. 
      The current PC and switch topology is shown
      <a href=doc/docwrapper.php3?docname=topo.html>here</a>.
<p>

The fifth ethernet port on each PC is connected to the
      <a href="#tbcorerouter">core router</a>.
      Thus each PC has a full duplex 100Mbps connection to the servers.
      These connections are for dumping 
      data off of the nodes and such, without interfering with
      the experimental interfaces. The only impact on the node is
      processor and disk use, and bandwidth on the PCI bus.
<p>


