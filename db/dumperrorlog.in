#!/usr/bin/perl -w
#
# EMULAB-COPYRIGHT
# Copyright (c) 2005, 2006 University of Utah and the Flux Group.
# All rights reserved.
#
use English;
use Getopt::Std;

#
# Check DB consistency.
#
sub usage() {
    print STDOUT "Usage: dumperrorlog [-d]\n";
    exit(-1);
}
my $optlist  = "df";
my $debug    = 0;
my $force    = 0;
my $tempfile = "/var/tmp/testbed_dumperrorlog_tempfile";

my $keep_important = 7 * 24 * 60 * 60;
my $keep_any       = 4 * 24 * 60 * 60;
my $max_rows       = 300000;

#
# Configure variables
#
my $TB		= "@prefix@";
my $TBOPS       = "@TBOPSEMAIL@";
my $ISMAINSITE  = @TBMAINSITE@;
my $USERNODE	= "@USERNODE@";
my $PROXY       = "$TB/sbin/dumperrorlog.proxy";
my $SCP         = "/usr/bin/scp";
my $SSHTB	= "$TB/bin/sshtb";

# un-taint path
$ENV{'PATH'} = '/bin:/usr/bin:/usr/local/bin:/usr/site/bin';
delete @ENV{'IFS', 'CDPATH', 'ENV', 'BASH_ENV'};

#
# Turn off line buffering on output
#
$| = 1; 

# Load the Testbed support stuff.
use lib "@prefix@/lib";
use libdb;
use libtestbed;

# Protos
sub fatal($);

#
# Only real root can call this.
# 
if ($UID != 0) {
    print STDERR "You must be root to run this script!\n";
    exit(-1);
}

#
# Form a temp name.
#
my $logname = TBMakeLogname("dumperrorlog");

#
# Parse command arguments. Once we return from getopts, all that should
# left are the required arguments.
#
%options = ();
if (! getopts($optlist, \%options)) {
    usage();
}
if (@ARGV) {
    usage();
}
if (defined($options{"d"})) {
    $debug++;
}
if (defined($options{"f"})) {
    $force++;
}

#
# Reopen both stdout and stderr so that we can record all the output for
# later mailing.
#
if (! $debug) {
    open(STDERR, ">> $logname") or die("opening $logname for STDERR: $!");
    open(STDOUT, ">> $logname") or die("opening $logname for STDOUT: $!");
}

#
# Get the last log index we archived out.
#
my $query_result =
    DBQueryFatal("select idx from emulab_indicies ".
		 "where name='lastlog_seqnum'");
my ($lastseq) = $query_result->fetchrow_array();
if (!defined($lastseq)) {
    DBQueryFatal("insert into emulab_indicies (name, idx) ".
		 "values ('lastlog_seqnum', 0)");
    $lastseq = 0;
}

#
# Limit number of rows to keep from locking the log table too long
#
my $maxseq = $lastseq + $max_rows;

#
# And the last experiment index we sent over.
#
$query_result =
    DBQueryFatal("select idx from emulab_indicies ".
		 "where name='lastlog_exptidx'");
my ($exptidx_min) = $query_result->fetchrow_array();
if (!defined($exptidx_min)) {
    DBQueryFatal("insert into emulab_indicies (name, idx) ".
		 "values ('lastlog_exptidx', 0)");
    $exptidx_min = 0;
}
# And the current largest one.
$query_result =
    DBQueryFatal("select MAX(exptidx) from experiment_stats");
my ($exptidx_max) = $query_result->fetchrow_array();
if (!defined($exptidx_max)) {
    fatal("Could not get largest experiment index!");
}

#
# Grab the index number for the NOTICE priority.
#
$query_result =
    DBQueryFatal("select priority from priorities ".
		 "where priority_name='NOTICE'");
my ($NOTICE) = $query_result->fetchrow_array();
if (!defined($NOTICE)) {
    fatal("No priority named 'NOTICE' in the priorities table!");
}

#
# Only the main site does this archiving stuff.
#
if ($ISMAINSITE) {
    #
    # Must lock the table of course
    #
    DBQueryFatal("lock tables log write");

    #
    # Grab all of the new entries and store to the file
    #
    DBQueryFatal("select * from log ".
		 "where seq > $lastseq " .
		 "and seq <= $maxseq " .
		 "into outfile '${tempfile}.log' ");

    #
    # Now we need to find out what the last index really was. 
    # 
    my $firstseq = $lastseq;
    
    $query_result =
	DBQueryFatal("select seq from log ".
		     "where seq > $lastseq " .
		     "  and seq <= $maxseq ".
		     "order by seq desc limit 1");
    # Save for later.
    ($lastseq) = $query_result->fetchrow_array();

    DBQueryFatal("unlock tables");

    #
    # Might not be any new entries ...
    # 
    if (defined($lastseq)) {
	system("echo \"load data infile '${tempfile}.log' into table log\" ".
	       "     | mysql errorlog");
	fatal("Could not load into archive DB!")
	    if ($?);

	# Okay, now that we have really archived them away, update the
	# seq number.
	DBQueryFatal("update emulab_indicies set idx='$lastseq' ".
		     "where name='lastlog_seqnum'");

	#
	# XXX This awful hack will go away when Kevin is happy with
	# the error logging code.
	#

	#
	# Copy the file over to ops and load it into the DB over there.
	#
	system("$SCP -p ${tempfile}.log ".
	       "     ${USERNODE}:/var/db/mysql/errorlog") == 0
	    or fatal("Could not copy $tempfile to $USERNODE!");

	system("$SSHTB -host $USERNODE $PROXY log") == 0
	    or fatal("Could not load log entries into ops DB!");
    }
    if (-e "${tempfile}.log") {
	unlink("${tempfile}.log.save")
	    if (-e "${tempfile}.log.save");
	
	system("/bin/mv -f ${tempfile}.log ${tempfile}.log.save");
    }

    #
    # Now the other tables Kevin needs
    #
    foreach my $tablename ("scripts", "priorities", "causes", "session_info",
			   "errors", "users", "experiments",
			   "report_error", "report_context",
			   "report_assign_violation") {
	if (($tablename eq "errors" ||
	     $tablename eq "session_info") && !$force) {
	    DBQueryFatal("select * from $tablename where session>=$firstseq and session<=$lastseq ".
			 "into outfile '${tempfile}.${tablename}' ");
	}
	elsif ($tablename eq "report_error" ||
	       $tablename eq "report_context" ||
	       $tablename eq "report_assign_violation") {
	    DBQueryFatal("select * from $tablename where seq>=$firstseq and seq<=$lastseq ".
			 "into outfile '${tempfile}.${tablename}' ");
	}
	elsif ($tablename eq "users") {
	    DBQueryFatal("select uid,unix_uid from $tablename ".
			 "into outfile '${tempfile}.${tablename}' ");
	}
	elsif ($tablename eq "experiments") {
	    next if
		($exptidx_max == $exptidx_min);
		
	    DBQueryFatal("select exptidx,pid,eid from experiment_stats ".
			 "where exptidx >  $exptidx_min and ".
			 "      exptidx <= $exptidx_max ".
			 "into outfile '${tempfile}.${tablename}' ");
	}
	else {
	    DBQueryFatal("select * from $tablename ".
			 "into outfile '${tempfile}.${tablename}' ");
	}

	system("echo \"load data infile '${tempfile}.${tablename}' ".
	       "     replace into table $tablename\" | mysql errorlog");
	fatal("Could not load $tablename into archive DB!")
	    if ($?);

	#
	# Copy the file over to ops and load it into the DB over there.
	#
	system("$SCP -p ${tempfile}.${tablename} ".
	       "     ${USERNODE}:/var/db/mysql/errorlog") == 0
	    or fatal("Could not copy ${tempfile}.${tablename} to $USERNODE!");

	system("$SSHTB -host $USERNODE $PROXY $tablename") == 0
	    or fatal("Could not load $tablename entries into ops DB!");
	
	unlink("${tempfile}.${tablename}");
    }
}

# Okay, now that we have really sent over the experiment_stats stuff.
DBQueryFatal("update emulab_indicies set idx='$exptidx_max' ".
		     "where name='lastlog_exptidx'");

#
# And then age out entries.
#
DBQueryFatal("delete from log ".
	     "where stamp < (UNIX_TIMESTAMP(now()) - $keep_important)".
	     "  and seq <= $maxseq");

#
# And age out non critical data.
#
DBQueryFatal("delete from log ".
	     "where priority > $NOTICE and ".
	     "      stamp < (UNIX_TIMESTAMP(now()) - $keep_any)".
	     "        and seq <= $maxseq");

unlink("$logname")
    if (-e $logname);

exit(0);

sub fatal($)
{
    my ($msg) = @_;

    SENDMAIL($TBOPS, "DumpErrorLog Failed", $msg, undef, undef, ($logname));
   
    unlink("$logname")
	if (-e $logname);

    die("*** $0:\n".
	"    $msg\n");
}
